# ML_Hw_1
В данном домашнем задании я обучал модель регрессии для предсказания стоимости автомобилей
____
## Часть №1
В этом задании я реализовал базовый EDA, обработку признаков, а также построил дашборды с помощью `ydata-profilling`.

- Пропуски в столбцах были заполнены медианам
- Удалены дубликаты
- Обновлены индексы
- ``mileage, engine, max_power`` приведены к типу данных ``float``
- Удален столбец ``torque``
- Столбцы ``engnine`` и ``seats`` к приведены к `int`
- Приведены основные статистики по числовым и категориальным признакам

## Визуализация
Построены графики зависимости всех числовых признаков. Распределения train и test внешне схожи.

Выдвинуты следующие предположения:
- `selling_price` прямо зависит от квадрата `year` (возможна квадратная зависимость)
- `selling_price` зависит от `engine` (возможно линейная регрессия)
- `selling_price` зависит от `max_power` (возможно линейная регрессия)

## Корреляция Пирсона
Были получены значения корреляции Пирсона, а также построена тепловая карта для визуализации.

По данным корреляции можно сказать следующее:
1. `engine` и `year` наименее скоррелированы между собой (корреляция близка к нулю)
2. Довольно сильная положительная линейная зависимость наблюдается между `max_power` и `selling_price`
3. Коэффициент корреляции между `year` и `km_driven` равен -0.37, это довольно высокое значение, значит корреляция присутствует, но так как -0.37 < 0, то значит зависимость обратная. Можно утверждать, что чем меньше год, тем, скорее всего, больше километров проехала машина к дате продажи
____
## Часть 2 | Модель на вещественных признаках
Для начала построим  модель только на вещественных признаках.
- Разделим датафрейм на `X_train`, `y_train`, `X_test`, `y_test`
- Обучим классическую линейную регрессию с дефолтными параметрами
- Посчтитаем  R2  и  MSE  для трейна и для теста
```
MSE для теста 233551443099.39868
MSE для train 117090306033.0161
R2 для тест 0.5937024338674333
R2 для треин 0.5915050767325436
```

Значение `MSE` по `y_test` значительно выше, чем аналогичное по `y_trai`n. В этом нет ничего удивительного, ведь модель обучалась на `y_train`, ошибка у нее будет ниже. Преимущество `MSE` - чувствительность к большим ошибкам.

Значения `R2` для трейна и для теста отличаются только в третьем знаке после запятой. Преимущество `R2` - инвариантность к масштабу данных. Значение близкое к 1 (как у нас, 0.59 в траине и в тесте) указывает на высокую степень соответствия модели данным.

## Стандартизация признаков
После стандартизации признаков и обучения модель показала следующие результаты:
```
MSE для теста 233551443099.39087
MSE для train 117090306033.01596
R2 для тест 0.5937024338674468
R2 для треин 0.591505076732544
```

Видим, что последние цифры у `MSE` стали меньше, а у `R2` больше. Это значит, что ошибка совсем немного уменьшилась и модель стала работать чуть лучше

Посмотрим коэффициенты с помощью `model.coef_`. Наиболее информативным признкаом является `max_power`

## Lasso
Попробуем улучшить нашу модель с помощью применения регуляризации. Для этого обучим `Lasso` регрессиею и оценим ее качество:
```
MSE для теста 233552116809.94913
MSE для train 117090306043.14563
R2 для тест 0.5937012618474564
R2 для треин 0.5915050766972044
```

Странно, но `MSE` выросло, а `R2` стало меньше. Это говорит о том, что `lasso` работает хуже. Коэффициенты не обнулились, лишь поменялись незначительно. Это говорит о том, что каждый показатель влияет на предсказание стоимости авто.

## Подбор оптимальных параметров
С помощью `GridSearchCV` перебором по сетке подберем оптимальные параметры для Lasso-регрессии. У нас 10 фолдов, те мы обучаем модель 10 раз для каждого гиперпараметра( их всего 5). Всего 50 моделей. Лучший alpha = 10. (-gs.best_score_ = 121547644891.48471)
```
MSE для тест: 233558188900.198
MSE для train: 117090307043.017
R2 для тест 0.593690698540903
R2 для треин 0.5915050732089362
```

Качество изменилось незначительно, параметры не занулились.

При переборе по сетке подберем оптимальные параметры для `ElasticNet` регрессии. Тк len(alpha) = len(l1_ratio) = 5, cv=10, то всего грид-сёрчу пришлось обучать (5^2)*10 = 250 моделей. Лучшие параметры `{'alpha': 0.5, 'l1_ratio': 0.8}`
____
## Часть 3| Категориальные фичи
Улучшим модель с помощью OneHot путем кодирования категориальных признаков. Удалим столбец `name`. Во избежание мультиколлинеарности удаляем один из полученных столбцов в X_train.

Столкнулся с проблемой, что при кодировании X_train у нас получается больше признаков, чем при кодировании X_test. После OneHot кодирования вручную добавлю недостающие пустые столбцы к X_test и отсортируем их согалсно X_train. Хоть и не самым простым путем, но теперь X_train и X_test сходятся, начинаем строить модель `Ridge`.

`-gs.best_score_ = 107376119246.52469, 'alpha': 10`

Никакие коэффициенты не занулились

```
MSE для тест: 206106535502.079
MSE для train: 99402746944.129
R2 для тест 0.6414469436488532
R2 для треин 0.6532119621066933
```
Мы видим значительное снижение `MSE` и рост `R2` (ошибки уменьшились примерно на 10%), что говорит нам о том, что после one-hot кодирования категориальных признаков наша модель стала значительно лучше предсказывать target.
____
## Часть 4. | Бизнесовая
Дадим оценку качества для бизнеса: среди всех предсказанных цен на авто нужно посчитать долю прогнозов, отличающихся от реальных цен на эти авто не более чем на 10% (в одну или другую сторону).

Метрика `business_metric` дает следующий результат:
```
Linear Regression 22.5 %
Lasso 22.5 %
Ridge 24.7 %
```
Доля прогнозов `Ridge` С ошибкой <= 10% равняется 24.7 %. Это больше, чем у `Linear Regression` и `Lasso`, а значит `Ridge` дает более точный прогноз.
____
## Результаты
В этой работе я форматирвоал данные, а также построил несколько моделей по предсказанию цены авто.

Модели `Linear Regression` и `Lasso` дают примерно одинаковую `MSE` и `R2` ошибку, бизнесметрика также оценивает их одинаково. Модель `Ridge` показала лучший результат после добавления категориальных признаков в анализ, показатель ошибки ниже чем у предыдущих моделей примерно на *~10%*, что не может не радовать!

Для меня самое сложное в этой работе было отформатировать данные к рабочему состоянию, стартовый датасет был достаточно грязным. На данный момент я не успел реализовать *Часть 5 | Реализация сервиса на FastAPI*, постараюсь загрузить что у меня получилось.

UPD: Спасибо, очень приятно! Потратил на эту домашку достаточно много времени. Предполагаю, что это кот *Елены Кантонистовой*